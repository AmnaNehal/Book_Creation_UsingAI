{"tag":{"label":"robotics","permalink":"/docs/tags/robotics","allTagsPath":"/docs/tags","count":6,"items":[{"id":"docs/vla-integration/capstone-humanoid","title":"Capstone: Autonomous Humanoid","description":"Complete VLA system overview with navigation, perception, and manipulation","permalink":"/docs/docs/vla-integration/capstone-humanoid"},{"id":"docs/ros2-nervous-system/urdf-modeling","title":"Humanoid Modeling with URDF","description":"Robot modeling using Unified Robot Description Format","permalink":"/docs/docs/ros2-nervous-system/urdf-modeling"},{"id":"docs/vla-integration/language-planning","title":"Language-Driven Planning","description":"Using LLMs for cognitive planning and task decomposition in robotics","permalink":"/docs/docs/vla-integration/language-planning"},{"id":"docs/ros2-nervous-system/python-agents","title":"Python Agents to ROS 2","description":"How Python AI agents communicate with ROS 2 using rclpy","permalink":"/docs/docs/ros2-nervous-system/python-agents"},{"id":"docs/ros2-nervous-system/fundamentals","title":"ROS 2 Fundamentals","description":"Core concepts of ROS 2 as middleware for AI agents and humanoid robot controllers","permalink":"/docs/docs/ros2-nervous-system/fundamentals"},{"id":"docs/vla-integration/voice-to-action","title":"Voice-to-Action Interfaces","description":"Using speech recognition and LLMs to convert voice commands to robotic actions","permalink":"/docs/docs/vla-integration/voice-to-action"}],"unlisted":false}}